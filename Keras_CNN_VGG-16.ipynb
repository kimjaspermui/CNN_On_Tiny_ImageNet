{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, ZeroPadding2D, BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses\n",
    "from keras import utils\n",
    "from keras import callbacks\n",
    "import keras\n",
    "import h5py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storing training:\n",
      "n02124075: 1 / 200\n",
      "n04067472: 2 / 200\n",
      "n04540053: 3 / 200\n",
      "n04099969: 4 / 200\n",
      "n07749582: 5 / 200\n",
      "n01641577: 6 / 200\n",
      "n02802426: 7 / 200\n",
      "n09246464: 8 / 200\n",
      "n07920052: 9 / 200\n",
      "n03970156: 10 / 200\n",
      "n03891332: 11 / 200\n",
      "n02106662: 12 / 200\n",
      "n03201208: 13 / 200\n",
      "n02279972: 14 / 200\n",
      "n02132136: 15 / 200\n",
      "n04146614: 16 / 200\n",
      "n07873807: 17 / 200\n",
      "n02364673: 18 / 200\n",
      "n04507155: 19 / 200\n",
      "n03854065: 20 / 200\n",
      "n03838899: 21 / 200\n",
      "n03733131: 22 / 200\n",
      "n01443537: 23 / 200\n",
      "n07875152: 24 / 200\n",
      "n03544143: 25 / 200\n",
      "n09428293: 26 / 200\n",
      "n03085013: 27 / 200\n",
      "n02437312: 28 / 200\n",
      "n07614500: 29 / 200\n",
      "n03804744: 30 / 200\n",
      "n04265275: 31 / 200\n",
      "n02963159: 32 / 200\n",
      "n02486410: 33 / 200\n",
      "n01944390: 34 / 200\n",
      "n09256479: 35 / 200\n",
      "n02058221: 36 / 200\n",
      "n04275548: 37 / 200\n",
      "n02321529: 38 / 200\n",
      "n02769748: 39 / 200\n",
      "n02099712: 40 / 200\n",
      "n07695742: 41 / 200\n",
      "n02056570: 42 / 200\n",
      "n02281406: 43 / 200\n",
      "n01774750: 44 / 200\n",
      "n02509815: 45 / 200\n",
      "n03983396: 46 / 200\n",
      "n07753592: 47 / 200\n",
      "n04254777: 48 / 200\n",
      "n02233338: 49 / 200\n",
      "n04008634: 50 / 200\n",
      "n02823428: 51 / 200\n",
      "n02236044: 52 / 200\n",
      "n03393912: 53 / 200\n",
      "n07583066: 54 / 200\n",
      "n04074963: 55 / 200\n",
      "n01629819: 56 / 200\n",
      "n09332890: 57 / 200\n",
      "n02481823: 58 / 200\n",
      "n03902125: 59 / 200\n",
      "n03404251: 60 / 200\n",
      "n09193705: 61 / 200\n",
      "n03637318: 62 / 200\n",
      "n04456115: 63 / 200\n",
      "n02666196: 64 / 200\n",
      "n03796401: 65 / 200\n",
      "n02795169: 66 / 200\n",
      "n02123045: 67 / 200\n",
      "n01855672: 68 / 200\n",
      "n01882714: 69 / 200\n",
      "n02917067: 70 / 200\n",
      "n02988304: 71 / 200\n",
      "n04398044: 72 / 200\n",
      "n02843684: 73 / 200\n",
      "n02423022: 74 / 200\n",
      "n02669723: 75 / 200\n",
      "n04465501: 76 / 200\n",
      "n02165456: 77 / 200\n",
      "n03770439: 78 / 200\n",
      "n02099601: 79 / 200\n",
      "n04486054: 80 / 200\n",
      "n02950826: 81 / 200\n",
      "n03814639: 82 / 200\n",
      "n04259630: 83 / 200\n",
      "n03424325: 84 / 200\n",
      "n02948072: 85 / 200\n",
      "n03179701: 86 / 200\n",
      "n03400231: 87 / 200\n",
      "n02206856: 88 / 200\n",
      "n03160309: 89 / 200\n",
      "n01984695: 90 / 200\n",
      "n03977966: 91 / 200\n",
      "n03584254: 92 / 200\n",
      "n04023962: 93 / 200\n",
      "n02814860: 94 / 200\n",
      "n01910747: 95 / 200\n",
      "n04596742: 96 / 200\n",
      "n03992509: 97 / 200\n",
      "n04133789: 98 / 200\n",
      "n03937543: 99 / 200\n",
      "n02927161: 100 / 200\n",
      "n01945685: 101 / 200\n",
      "n02395406: 102 / 200\n",
      "n02125311: 103 / 200\n",
      "n03126707: 104 / 200\n",
      "n04532106: 105 / 200\n",
      "n02268443: 106 / 200\n",
      "n02977058: 107 / 200\n",
      "n07734744: 108 / 200\n",
      "n03599486: 109 / 200\n",
      "n04562935: 110 / 200\n",
      "n03014705: 111 / 200\n",
      "n04251144: 112 / 200\n",
      "n04356056: 113 / 200\n",
      "n02190166: 114 / 200\n",
      "n03670208: 115 / 200\n",
      "n02002724: 116 / 200\n",
      "n02074367: 117 / 200\n",
      "n04285008: 118 / 200\n",
      "n04560804: 119 / 200\n",
      "n04366367: 120 / 200\n",
      "n02403003: 121 / 200\n",
      "n07615774: 122 / 200\n",
      "n04501370: 123 / 200\n",
      "n03026506: 124 / 200\n",
      "n02906734: 125 / 200\n",
      "n01770393: 126 / 200\n",
      "n04597913: 127 / 200\n",
      "n03930313: 128 / 200\n",
      "n04118538: 129 / 200\n",
      "n04179913: 130 / 200\n",
      "n04311004: 131 / 200\n",
      "n02123394: 132 / 200\n",
      "n04070727: 133 / 200\n",
      "n02793495: 134 / 200\n",
      "n02730930: 135 / 200\n",
      "n02094433: 136 / 200\n",
      "n04371430: 137 / 200\n",
      "n04328186: 138 / 200\n",
      "n03649909: 139 / 200\n",
      "n04417672: 140 / 200\n",
      "n03388043: 141 / 200\n",
      "n01774384: 142 / 200\n",
      "n02837789: 143 / 200\n",
      "n07579787: 144 / 200\n",
      "n04399382: 145 / 200\n",
      "n02791270: 146 / 200\n",
      "n03089624: 147 / 200\n",
      "n02814533: 148 / 200\n",
      "n04149813: 149 / 200\n",
      "n07747607: 150 / 200\n",
      "n03355925: 151 / 200\n",
      "n01983481: 152 / 200\n",
      "n04487081: 153 / 200\n",
      "n03250847: 154 / 200\n",
      "n03255030: 155 / 200\n",
      "n02892201: 156 / 200\n",
      "n02883205: 157 / 200\n",
      "n03100240: 158 / 200\n",
      "n02415577: 159 / 200\n",
      "n02480495: 160 / 200\n",
      "n01698640: 161 / 200\n",
      "n01784675: 162 / 200\n",
      "n04376876: 163 / 200\n",
      "n03444034: 164 / 200\n",
      "n01917289: 165 / 200\n",
      "n01950731: 166 / 200\n",
      "n03042490: 167 / 200\n",
      "n07711569: 168 / 200\n",
      "n04532670: 169 / 200\n",
      "n03763968: 170 / 200\n",
      "n07768694: 171 / 200\n",
      "n02999410: 172 / 200\n",
      "n03617480: 173 / 200\n",
      "n06596364: 174 / 200\n",
      "n01768244: 175 / 200\n",
      "n02410509: 176 / 200\n",
      "n03976657: 177 / 200\n",
      "n01742172: 178 / 200\n",
      "n03980874: 179 / 200\n",
      "n02808440: 180 / 200\n",
      "n02226429: 181 / 200\n",
      "n02231487: 182 / 200\n",
      "n02085620: 183 / 200\n",
      "n01644900: 184 / 200\n",
      "n02129165: 185 / 200\n",
      "n02699494: 186 / 200\n",
      "n03837869: 187 / 200\n",
      "n02815834: 188 / 200\n",
      "n07720875: 189 / 200\n",
      "n02788148: 190 / 200\n",
      "n02909870: 191 / 200\n",
      "n03706229: 192 / 200\n",
      "n07871810: 193 / 200\n",
      "n03447447: 194 / 200\n",
      "n02113799: 195 / 200\n",
      "n12267677: 196 / 200\n",
      "n03662601: 197 / 200\n",
      "n02841315: 198 / 200\n",
      "n07715103: 199 / 200\n",
      "n02504458: 200 / 200\n",
      "storing validation:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "# constants\n",
    "CLASS = 200\n",
    "SAMPLES_PER_CLASS = 500\n",
    "TOTAL_SAMPLES = CLASS * SAMPLES_PER_CLASS\n",
    "COLOR_CHANNELS = 3\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_HEIGHT = 64\n",
    "VAL_SAMPLES = 10000\n",
    "\n",
    "# read all of the word net id\n",
    "wnids = [id.strip('\\n') for id in open('/datasets/tmp/cg181fdn/tiny-imagenet-200/wnids.txt').readlines()]\n",
    "\n",
    "# data will store all of the data\n",
    "data = {}\n",
    "\n",
    "# train data\n",
    "data['train'] = {}\n",
    "data['train']['data'] = np.ndarray(shape=(TOTAL_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, COLOR_CHANNELS), dtype=np.uint8)\n",
    "data['train']['target'] = np.ndarray(shape=(TOTAL_SAMPLES,), dtype=np.uint8)\n",
    "\n",
    "# validation data\n",
    "data['val'] = {}\n",
    "data['val']['data'] = np.ndarray(shape=(VAL_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, COLOR_CHANNELS), dtype=np.uint8)\n",
    "data['val']['target'] = np.ndarray(shape=(VAL_SAMPLES,), dtype=np.uint8)\n",
    "\n",
    "# iterate through work net ids\n",
    "print(\"storing training:\")\n",
    "for i in range(len(wnids)):\n",
    "    wnid = wnids[i]\n",
    "    print(\"%s: %d / %d\" % (wnid, i + 1, len(wnids)))\n",
    "    for j in range(500):\n",
    "        temp = []\n",
    "        path = \"/datasets/tmp/cg181fdn/tiny-imagenet-200/train/{0}/images/{0}_{1}.JPEG\".format(wnid, j)\n",
    "        data['train']['data'][i * SAMPLES_PER_CLASS + j] = np.array(Image.open(path).convert('RGB'))\n",
    "        data['train']['target'][i * SAMPLES_PER_CLASS + j] = wnids.index(wnid)\n",
    "\n",
    "# get the validation data\n",
    "print(\"storing validation:\")\n",
    "for i, line in enumerate(map(lambda s: s.strip(), open('/datasets/tmp/cg181fdn/tiny-imagenet-200/val/val_annotations.txt'))):\n",
    "    name, wnid = line.split('\\t')[0:2]\n",
    "    temp = []\n",
    "    path = \"/datasets/tmp/cg181fdn/tiny-imagenet-200/val/images/{0}\".format(name)\n",
    "    data['val']['data'][i] = np.array(Image.open(path).convert('RGB'))\n",
    "    data['val']['target'][i] = wnids.index(wnid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_like():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-6,l2=1e-6)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(200, activation='softmax',\n",
    "                   kernel_regularizer=regularizers.l1_l2(l1=1e-5,l2=1e-5)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_16():    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1), input_shape=(64,64,3)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name=\"conv1_1\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name=\"conv1_2\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), name=\"block1_pool\"))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', name=\"conv2_1\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', name=\"conv2_2\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), name=\"block2_pool\"))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', name=\"conv3_1\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', name=\"conv3_2\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', name=\"conv3_3\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), name=\"block3_pool\"))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', name=\"conv4_1\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', name=\"conv4_2\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', name=\"conv4_3\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), name=\"block4_pool\"))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu',\n",
    "                     kernel_regularizer=regularizers.l1_l2(l1=1e-7,l2=1e-7), name=\"conv5_1\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu',\n",
    "                     kernel_regularizer=regularizers.l1_l2(l1=1e-6,l2=1e-6), name=\"conv5_2\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu',\n",
    "                     kernel_regularizer=regularizers.l1_l2(l1=1e-5,l2=1e-5), name=\"conv5_3\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), name=\"block5_pool\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-4,l2=1e-4), name=\"fc6\"))\n",
    "    model.add(Dropout(0.75, name=\"drop6\"))\n",
    "    model.add(Dense(4096, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-4,l2=1e-4), name=\"fc7\"))\n",
    "    model.add(Dropout(0.75, name=\"drop7\"))\n",
    "    model.add(Dense(200, activation='softmax', name=\"fc8\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=96, kernel_size=(7, 7), activation='relu', input_shape=(64,64,3)))    \n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1,1)))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=(7, 7), activation='relu'))    \n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1,1)))\n",
    "\n",
    "    model.add(Conv2D(filters=192, kernel_size=(3, 3), activation='relu'))    \n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1,1)))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))    \n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1,1)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(Dense(200, activation='softmax', name=\"fc8\"))\n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 41.2651 - acc: 0.0049\n",
      "Testing loss: 40.3089189026, acc: 0.0059\n",
      "\n",
      "100000/100000 [==============================] - 138s - loss: 41.2648 - acc: 0.0049   \n",
      "Epoch 2/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 39.3523 - acc: 0.0050\n",
      "Testing loss: 38.3923794312, acc: 0.0069\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 39.3520 - acc: 0.0050   \n",
      "Epoch 3/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 37.4575 - acc: 0.0056\n",
      "Testing loss: 36.525319104, acc: 0.0104\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 37.4572 - acc: 0.0056   \n",
      "Epoch 4/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 35.6528 - acc: 0.0066\n",
      "Testing loss: 34.7930457764, acc: 0.0139\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 35.6525 - acc: 0.0066   \n",
      "Epoch 5/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 34.0428 - acc: 0.0082\n",
      "Testing loss: 33.2696207642, acc: 0.0101\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 34.0425 - acc: 0.0082   \n",
      "Epoch 6/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 32.6022 - acc: 0.0098\n",
      "Testing loss: 31.8874945892, acc: 0.0114\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 32.6020 - acc: 0.0098   \n",
      "Epoch 7/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 31.3014 - acc: 0.0107\n",
      "Testing loss: 30.6247623169, acc: 0.0109\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 31.3012 - acc: 0.0107   \n",
      "Epoch 8/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 30.0946 - acc: 0.0118\n",
      "Testing loss: 29.4558620911, acc: 0.0138\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 30.0944 - acc: 0.0118   \n",
      "Epoch 9/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 28.9530 - acc: 0.0127\n",
      "Testing loss: 28.3449438629, acc: 0.0173\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 28.9528 - acc: 0.0127   \n",
      "Epoch 10/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 27.8752 - acc: 0.0138\n",
      "Testing loss: 27.2986287384, acc: 0.0211\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 27.8750 - acc: 0.0138   \n",
      "Epoch 11/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 26.8680 - acc: 0.0152\n",
      "Testing loss: 26.3335396851, acc: 0.0285\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 26.8679 - acc: 0.0152   \n",
      "Epoch 12/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 25.9260 - acc: 0.0178\n",
      "Testing loss: 25.4000517761, acc: 0.0259\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 25.9257 - acc: 0.0178   \n",
      "Epoch 13/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 25.0612 - acc: 0.0196\n",
      "Testing loss: 24.5729237366, acc: 0.0361\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 25.0612 - acc: 0.0196   \n",
      "Epoch 14/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 24.2650 - acc: 0.0227\n",
      "Testing loss: 23.7976635223, acc: 0.0395\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 24.2649 - acc: 0.0227   \n",
      "Epoch 15/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 23.5327 - acc: 0.0242\n",
      "Testing loss: 23.1033026001, acc: 0.0383\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 23.5326 - acc: 0.0242   \n",
      "Epoch 16/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 22.8527 - acc: 0.0281\n",
      "Testing loss: 22.4628695984, acc: 0.0387\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 22.8526 - acc: 0.0282   \n",
      "Epoch 17/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 22.2174 - acc: 0.0304\n",
      "Testing loss: 21.8389314148, acc: 0.0432\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 22.2173 - acc: 0.0304   \n",
      "Epoch 18/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 21.6275 - acc: 0.0342\n",
      "Testing loss: 21.2370737488, acc: 0.0559\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 21.6275 - acc: 0.0342   \n",
      "Epoch 19/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 21.0846 - acc: 0.0357\n",
      "Testing loss: 20.7302486633, acc: 0.0518\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 21.0844 - acc: 0.0357   \n",
      "Epoch 20/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 20.5681 - acc: 0.0394\n",
      "Testing loss: 20.189003479, acc: 0.0559\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 20.5680 - acc: 0.0394   \n",
      "Epoch 21/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 20.0922 - acc: 0.0412\n",
      "Testing loss: 19.6964002075, acc: 0.0643\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 20.0920 - acc: 0.0412   \n",
      "Epoch 22/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 19.6376 - acc: 0.0441\n",
      "Testing loss: 19.3024962585, acc: 0.0643\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 19.6376 - acc: 0.0441   \n",
      "Epoch 23/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 19.2143 - acc: 0.0463\n",
      "Testing loss: 18.8589462555, acc: 0.0695\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 19.2141 - acc: 0.0463   \n",
      "Epoch 24/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 18.8143 - acc: 0.0484\n",
      "Testing loss: 18.4366472748, acc: 0.0737\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 18.8142 - acc: 0.0484   \n",
      "Epoch 25/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 18.4365 - acc: 0.0514\n",
      "Testing loss: 18.1101572784, acc: 0.077\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 18.4365 - acc: 0.0514   \n",
      "Epoch 26/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 18.0765 - acc: 0.0528\n",
      "Testing loss: 17.7831632874, acc: 0.0701\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 18.0764 - acc: 0.0528   \n",
      "Epoch 27/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 17.7322 - acc: 0.0558\n",
      "Testing loss: 17.4303268402, acc: 0.0827\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 17.7323 - acc: 0.0558   \n",
      "Epoch 28/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 17.4112 - acc: 0.0584\n",
      "Testing loss: 17.0890167267, acc: 0.0875\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 17.4111 - acc: 0.0584   \n",
      "Epoch 29/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 17.1057 - acc: 0.0603\n",
      "Testing loss: 16.8177271118, acc: 0.0819\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 17.1057 - acc: 0.0602   \n",
      "Epoch 30/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 16.8140 - acc: 0.0623\n",
      "Testing loss: 16.475177533, acc: 0.0978\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 16.8140 - acc: 0.0624   \n",
      "Epoch 31/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 16.5331 - acc: 0.0650\n",
      "Testing loss: 16.2883930817, acc: 0.0876\n",
      "\n",
      "100000/100000 [==============================] - 130s - loss: 16.5330 - acc: 0.0650   \n",
      "Epoch 32/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 16.2697 - acc: 0.0667\n",
      "Testing loss: 15.9479298065, acc: 0.1002\n",
      "\n",
      "100000/100000 [==============================] - 129s - loss: 16.2696 - acc: 0.0667   \n",
      "Epoch 33/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 16.0189 - acc: 0.0709\n",
      "Testing loss: 15.87534189, acc: 0.0791\n",
      "\n",
      "100000/100000 [==============================] - 129s - loss: 16.0188 - acc: 0.0709   \n",
      "Epoch 34/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 15.7742 - acc: 0.0730\n",
      "Testing loss: 15.4756311859, acc: 0.1087\n",
      "\n",
      "100000/100000 [==============================] - 129s - loss: 15.7742 - acc: 0.0729   \n",
      "Epoch 35/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 15.5520 - acc: 0.0742\n",
      "Testing loss: 15.2581591827, acc: 0.1065\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 15.5519 - acc: 0.0742   \n",
      "Epoch 36/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 15.3279 - acc: 0.0763\n",
      "Testing loss: 15.0242889984, acc: 0.1164\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 128s - loss: 15.3278 - acc: 0.0763   \n",
      "Epoch 37/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 15.1181 - acc: 0.0799\n",
      "Testing loss: 14.888698175, acc: 0.1064\n",
      "\n",
      "100000/100000 [==============================] - 129s - loss: 15.1182 - acc: 0.0799   \n",
      "Epoch 38/100\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 14.9137 - acc: 0.0808\n",
      "Testing loss: 14.665787619, acc: 0.1109\n",
      "\n",
      "100000/100000 [==============================] - 128s - loss: 14.9137 - acc: 0.0808   \n",
      "Epoch 39/100\n",
      " 39552/100000 [==========>...................] - ETA: 74s - loss: 14.7733 - acc: 0.0836"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-39fedd689420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                 metrics=['accuracy'])\n\u001b[1;32m     15\u001b[0m hist = myModel.fit(x=training_images, y=training_labels, batch_size=128,\n\u001b[0;32m---> 16\u001b[0;31m                  epochs=100, callbacks=[TestCallback((val_images, val_labels))])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shuffle_train_index = np.random.permutation(len(data['train']['data']))\n",
    "training_images = np.array(data['train']['data'])[shuffle_train_index]\n",
    "training_labels = np.array(data['train']['target'])[shuffle_train_index]\n",
    "training_labels = utils.to_categorical(training_labels, num_classes=200)\n",
    "\n",
    "val_images = np.array(data['val']['data'])\n",
    "val_labels = np.array(data['val']['target'])\n",
    "val_labels = utils.to_categorical(val_labels, num_classes=200)\n",
    "\n",
    "myModel = vgg_16()\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "op = keras.optimizers.Adadelta(lr=0.01, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "myModel.compile(loss='categorical_crossentropy', optimizer=op,\n",
    "                metrics=['accuracy'])\n",
    "hist = myModel.fit(x=training_images, y=training_labels, batch_size=128,\n",
    "                 epochs=100, callbacks=[TestCallback((val_images, val_labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pretrain:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
