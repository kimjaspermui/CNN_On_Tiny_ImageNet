{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense,Flatten\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses\n",
    "from keras import utils\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storing training:\n",
      "n02124075: 1 / 200\n",
      "n04067472: 2 / 200\n",
      "n04540053: 3 / 200\n",
      "n04099969: 4 / 200\n",
      "n07749582: 5 / 200\n",
      "n01641577: 6 / 200\n",
      "n02802426: 7 / 200\n",
      "n09246464: 8 / 200\n",
      "n07920052: 9 / 200\n",
      "n03970156: 10 / 200\n",
      "n03891332: 11 / 200\n",
      "n02106662: 12 / 200\n",
      "n03201208: 13 / 200\n",
      "n02279972: 14 / 200\n",
      "n02132136: 15 / 200\n",
      "n04146614: 16 / 200\n",
      "n07873807: 17 / 200\n",
      "n02364673: 18 / 200\n",
      "n04507155: 19 / 200\n",
      "n03854065: 20 / 200\n",
      "n03838899: 21 / 200\n",
      "n03733131: 22 / 200\n",
      "n01443537: 23 / 200\n",
      "n07875152: 24 / 200\n",
      "n03544143: 25 / 200\n",
      "n09428293: 26 / 200\n",
      "n03085013: 27 / 200\n",
      "n02437312: 28 / 200\n",
      "n07614500: 29 / 200\n",
      "n03804744: 30 / 200\n",
      "n04265275: 31 / 200\n",
      "n02963159: 32 / 200\n",
      "n02486410: 33 / 200\n",
      "n01944390: 34 / 200\n",
      "n09256479: 35 / 200\n",
      "n02058221: 36 / 200\n",
      "n04275548: 37 / 200\n",
      "n02321529: 38 / 200\n",
      "n02769748: 39 / 200\n",
      "n02099712: 40 / 200\n",
      "n07695742: 41 / 200\n",
      "n02056570: 42 / 200\n",
      "n02281406: 43 / 200\n",
      "n01774750: 44 / 200\n",
      "n02509815: 45 / 200\n",
      "n03983396: 46 / 200\n",
      "n07753592: 47 / 200\n",
      "n04254777: 48 / 200\n",
      "n02233338: 49 / 200\n",
      "n04008634: 50 / 200\n",
      "n02823428: 51 / 200\n",
      "n02236044: 52 / 200\n",
      "n03393912: 53 / 200\n",
      "n07583066: 54 / 200\n",
      "n04074963: 55 / 200\n",
      "n01629819: 56 / 200\n",
      "n09332890: 57 / 200\n",
      "n02481823: 58 / 200\n",
      "n03902125: 59 / 200\n",
      "n03404251: 60 / 200\n",
      "n09193705: 61 / 200\n",
      "n03637318: 62 / 200\n",
      "n04456115: 63 / 200\n",
      "n02666196: 64 / 200\n",
      "n03796401: 65 / 200\n",
      "n02795169: 66 / 200\n",
      "n02123045: 67 / 200\n",
      "n01855672: 68 / 200\n",
      "n01882714: 69 / 200\n",
      "n02917067: 70 / 200\n",
      "n02988304: 71 / 200\n",
      "n04398044: 72 / 200\n",
      "n02843684: 73 / 200\n",
      "n02423022: 74 / 200\n",
      "n02669723: 75 / 200\n",
      "n04465501: 76 / 200\n",
      "n02165456: 77 / 200\n",
      "n03770439: 78 / 200\n",
      "n02099601: 79 / 200\n",
      "n04486054: 80 / 200\n",
      "n02950826: 81 / 200\n",
      "n03814639: 82 / 200\n",
      "n04259630: 83 / 200\n",
      "n03424325: 84 / 200\n",
      "n02948072: 85 / 200\n",
      "n03179701: 86 / 200\n",
      "n03400231: 87 / 200\n",
      "n02206856: 88 / 200\n",
      "n03160309: 89 / 200\n",
      "n01984695: 90 / 200\n",
      "n03977966: 91 / 200\n",
      "n03584254: 92 / 200\n",
      "n04023962: 93 / 200\n",
      "n02814860: 94 / 200\n",
      "n01910747: 95 / 200\n",
      "n04596742: 96 / 200\n",
      "n03992509: 97 / 200\n",
      "n04133789: 98 / 200\n",
      "n03937543: 99 / 200\n",
      "n02927161: 100 / 200\n",
      "n01945685: 101 / 200\n",
      "n02395406: 102 / 200\n",
      "n02125311: 103 / 200\n",
      "n03126707: 104 / 200\n",
      "n04532106: 105 / 200\n",
      "n02268443: 106 / 200\n",
      "n02977058: 107 / 200\n",
      "n07734744: 108 / 200\n",
      "n03599486: 109 / 200\n",
      "n04562935: 110 / 200\n",
      "n03014705: 111 / 200\n",
      "n04251144: 112 / 200\n",
      "n04356056: 113 / 200\n",
      "n02190166: 114 / 200\n",
      "n03670208: 115 / 200\n",
      "n02002724: 116 / 200\n",
      "n02074367: 117 / 200\n",
      "n04285008: 118 / 200\n",
      "n04560804: 119 / 200\n",
      "n04366367: 120 / 200\n",
      "n02403003: 121 / 200\n",
      "n07615774: 122 / 200\n",
      "n04501370: 123 / 200\n",
      "n03026506: 124 / 200\n",
      "n02906734: 125 / 200\n",
      "n01770393: 126 / 200\n",
      "n04597913: 127 / 200\n",
      "n03930313: 128 / 200\n",
      "n04118538: 129 / 200\n",
      "n04179913: 130 / 200\n",
      "n04311004: 131 / 200\n",
      "n02123394: 132 / 200\n",
      "n04070727: 133 / 200\n",
      "n02793495: 134 / 200\n",
      "n02730930: 135 / 200\n",
      "n02094433: 136 / 200\n",
      "n04371430: 137 / 200\n",
      "n04328186: 138 / 200\n",
      "n03649909: 139 / 200\n",
      "n04417672: 140 / 200\n",
      "n03388043: 141 / 200\n",
      "n01774384: 142 / 200\n",
      "n02837789: 143 / 200\n",
      "n07579787: 144 / 200\n",
      "n04399382: 145 / 200\n",
      "n02791270: 146 / 200\n",
      "n03089624: 147 / 200\n",
      "n02814533: 148 / 200\n",
      "n04149813: 149 / 200\n",
      "n07747607: 150 / 200\n",
      "n03355925: 151 / 200\n",
      "n01983481: 152 / 200\n",
      "n04487081: 153 / 200\n",
      "n03250847: 154 / 200\n",
      "n03255030: 155 / 200\n",
      "n02892201: 156 / 200\n",
      "n02883205: 157 / 200\n",
      "n03100240: 158 / 200\n",
      "n02415577: 159 / 200\n",
      "n02480495: 160 / 200\n",
      "n01698640: 161 / 200\n",
      "n01784675: 162 / 200\n",
      "n04376876: 163 / 200\n",
      "n03444034: 164 / 200\n",
      "n01917289: 165 / 200\n",
      "n01950731: 166 / 200\n",
      "n03042490: 167 / 200\n",
      "n07711569: 168 / 200\n",
      "n04532670: 169 / 200\n",
      "n03763968: 170 / 200\n",
      "n07768694: 171 / 200\n",
      "n02999410: 172 / 200\n",
      "n03617480: 173 / 200\n",
      "n06596364: 174 / 200\n",
      "n01768244: 175 / 200\n",
      "n02410509: 176 / 200\n",
      "n03976657: 177 / 200\n",
      "n01742172: 178 / 200\n",
      "n03980874: 179 / 200\n",
      "n02808440: 180 / 200\n",
      "n02226429: 181 / 200\n",
      "n02231487: 182 / 200\n",
      "n02085620: 183 / 200\n",
      "n01644900: 184 / 200\n",
      "n02129165: 185 / 200\n",
      "n02699494: 186 / 200\n",
      "n03837869: 187 / 200\n",
      "n02815834: 188 / 200\n",
      "n07720875: 189 / 200\n",
      "n02788148: 190 / 200\n",
      "n02909870: 191 / 200\n",
      "n03706229: 192 / 200\n",
      "n07871810: 193 / 200\n",
      "n03447447: 194 / 200\n",
      "n02113799: 195 / 200\n",
      "n12267677: 196 / 200\n",
      "n03662601: 197 / 200\n",
      "n02841315: 198 / 200\n",
      "n07715103: 199 / 200\n",
      "n02504458: 200 / 200\n",
      "storing validation:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "# constants\n",
    "CLASS = 200\n",
    "SAMPLES_PER_CLASS = 500\n",
    "TOTAL_SAMPLES = CLASS * SAMPLES_PER_CLASS\n",
    "COLOR_CHANNELS = 3\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_HEIGHT = 64\n",
    "VAL_SAMPLES = 10000\n",
    "\n",
    "# read all of the word net id\n",
    "wnids = [id.strip('\\n') for id in open('/datasets/tmp/cg181fdn/tiny-imagenet-200/wnids.txt').readlines()]\n",
    "\n",
    "# data will store all of the data\n",
    "data = {}\n",
    "\n",
    "# train data\n",
    "data['train'] = {}\n",
    "data['train']['data'] = np.ndarray(shape=(TOTAL_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, COLOR_CHANNELS), dtype=np.uint8)\n",
    "data['train']['target'] = np.ndarray(shape=(TOTAL_SAMPLES,), dtype=np.uint8)\n",
    "\n",
    "# validation data\n",
    "data['val'] = {}\n",
    "data['val']['data'] = np.ndarray(shape=(VAL_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, COLOR_CHANNELS), dtype=np.uint8)\n",
    "data['val']['target'] = np.ndarray(shape=(VAL_SAMPLES,), dtype=np.uint8)\n",
    "\n",
    "# iterate through work net ids\n",
    "print(\"storing training:\")\n",
    "for i in range(len(wnids)):\n",
    "    wnid = wnids[i]\n",
    "    print(\"%s: %d / %d\" % (wnid, i + 1, len(wnids)))\n",
    "    for j in range(500):\n",
    "        temp = []\n",
    "        path = \"/datasets/tmp/cg181fdn/tiny-imagenet-200/train/{0}/images/{0}_{1}.JPEG\".format(wnid, j)\n",
    "        test = np.array(Image.open(path).convert('RGB'))\n",
    "        data['train']['data'][i * SAMPLES_PER_CLASS + j] = test\n",
    "        data['train']['target'][i * SAMPLES_PER_CLASS + j] = i\n",
    "\n",
    "# get the validation data\n",
    "print(\"storing validation:\")\n",
    "for i, line in enumerate(map(lambda s: s.strip(), open('/datasets/tmp/cg181fdn/tiny-imagenet-200/val/val_annotations.txt'))):\n",
    "    name, wnid = line.split('\\t')[0:2]\n",
    "    temp = []\n",
    "    path = \"/datasets/tmp/cg181fdn/tiny-imagenet-200/val/images/{0}\".format(name)\n",
    "    test = np.array(Image.open(path).convert('RGB'))\n",
    "    data['val']['data'][i] = test\n",
    "    data['val']['target'][i] = wnids.index(wnid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_train_index = np.random.permutation(len(data['train']['data']))\n",
    "training_images = np.array(data['train']['data'])[shuffle_train_index]\n",
    "training_labels = np.array(data['train']['target'])[shuffle_train_index]\n",
    "training_labels = utils.to_categorical(training_labels, num_classes=200)\n",
    "\n",
    "val_images = np.array(data['val']['data'])\n",
    "val_labels = np.array(data['val']['target'])\n",
    "val_labels = utils.to_categorical(val_labels, num_classes=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 12.2027 - acc: 0.0055\n",
      "Testing loss: 5.30729685822, acc: 0.0047\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 12.2006 - acc: 0.0055    \n",
      "Epoch 2/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3719 - acc: 0.0050\n",
      "Testing loss: 5.29912235718, acc: 0.0048\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3719 - acc: 0.0050    \n",
      "Epoch 3/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3253 - acc: 0.0046\n",
      "Testing loss: 5.29838058319, acc: 0.0036\n",
      "\n",
      "100000/100000 [==============================] - 26s - loss: 5.3252 - acc: 0.0046    \n",
      "Epoch 4/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3136 - acc: 0.0050\n",
      "Testing loss: 5.2983504425, acc: 0.004\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3136 - acc: 0.0050    \n",
      "Epoch 5/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3085 - acc: 0.0050\n",
      "Testing loss: 5.29835791626, acc: 0.0046\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3085 - acc: 0.0050    \n",
      "Epoch 6/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3058 - acc: 0.0050\n",
      "Testing loss: 5.2982729187, acc: 0.0044\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3058 - acc: 0.0050    \n",
      "Epoch 7/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3045 - acc: 0.0051\n",
      "Testing loss: 5.29826592255, acc: 0.005\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3045 - acc: 0.0050    \n",
      "Epoch 8/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3033 - acc: 0.0049\n",
      "Testing loss: 5.2982671608, acc: 0.0047\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3033 - acc: 0.0049    \n",
      "Epoch 9/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3027 - acc: 0.0048\n",
      "Testing loss: 5.29825609741, acc: 0.0047\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3027 - acc: 0.0047    \n",
      "Epoch 10/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3020 - acc: 0.0048\n",
      "Testing loss: 5.29822615433, acc: 0.0047\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3020 - acc: 0.0048    \n",
      "Epoch 11/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3019 - acc: 0.0045\n",
      "Testing loss: 5.29822034454, acc: 0.0043\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3019 - acc: 0.0045    \n",
      "Epoch 12/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3015 - acc: 0.0048\n",
      "Testing loss: 5.29822446899, acc: 0.0043\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3015 - acc: 0.0048    \n",
      "Epoch 13/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3012 - acc: 0.0047\n",
      "Testing loss: 5.2982136322, acc: 0.0046\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3012 - acc: 0.0047    \n",
      "Epoch 14/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3009 - acc: 0.0044\n",
      "Testing loss: 5.29823909149, acc: 0.0045\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3009 - acc: 0.0044    \n",
      "Epoch 15/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3010 - acc: 0.0048\n",
      "Testing loss: 5.29824806366, acc: 0.0043\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3010 - acc: 0.0048    \n",
      "Epoch 16/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3004 - acc: 0.0047\n",
      "Testing loss: 5.2982248909, acc: 0.0042\n",
      "\n",
      "100000/100000 [==============================] - 24s - loss: 5.3004 - acc: 0.0047    \n",
      "Epoch 17/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3000 - acc: 0.0046\n",
      "Testing loss: 5.29819875946, acc: 0.0045\n",
      "\n",
      "100000/100000 [==============================] - 24s - loss: 5.3001 - acc: 0.0046    \n",
      "Epoch 18/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.3006 - acc: 0.0052\n",
      "Testing loss: 5.29823158722, acc: 0.0045\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.3006 - acc: 0.0052    \n",
      "Epoch 19/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2999 - acc: 0.0054\n",
      "Testing loss: 5.29820224304, acc: 0.0054\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2999 - acc: 0.0054    \n",
      "Epoch 20/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2997 - acc: 0.0050\n",
      "Testing loss: 5.29819766617, acc: 0.0045\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2997 - acc: 0.0050    \n",
      "Epoch 21/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2996 - acc: 0.0048\n",
      "Testing loss: 5.29823219681, acc: 0.0046\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2996 - acc: 0.0048    \n",
      "Epoch 22/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2996 - acc: 0.0046\n",
      "Testing loss: 5.29821249847, acc: 0.0054\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2996 - acc: 0.0046    \n",
      "Epoch 23/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2994 - acc: 0.0049\n",
      "Testing loss: 5.29821815414, acc: 0.0045\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2994 - acc: 0.0049    \n",
      "Epoch 24/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2991 - acc: 0.0052\n",
      "Testing loss: 5.29817691498, acc: 0.0058\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2991 - acc: 0.0052    \n",
      "Epoch 25/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2995 - acc: 0.0049\n",
      "Testing loss: 5.29825856018, acc: 0.0053\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2995 - acc: 0.0049    \n",
      "Epoch 26/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2995 - acc: 0.0049\n",
      "Testing loss: 5.29819353256, acc: 0.0056\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2995 - acc: 0.0049    \n",
      "Epoch 27/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2994 - acc: 0.0052\n",
      "Testing loss: 5.29821817474, acc: 0.0054\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2994 - acc: 0.0052    \n",
      "Epoch 28/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2988 - acc: 0.0059\n",
      "Testing loss: 5.29817779846, acc: 0.0056\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2988 - acc: 0.0059    \n",
      "Epoch 29/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2989 - acc: 0.0052\n",
      "Testing loss: 5.2981693718, acc: 0.0054\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2989 - acc: 0.0052    \n",
      "Epoch 30/30\n",
      " 99968/100000 [============================>.] - ETA: 0s - loss: 5.2991 - acc: 0.0049\n",
      "Testing loss: 5.29819356079, acc: 0.0056\n",
      "\n",
      "100000/100000 [==============================] - 25s - loss: 5.2991 - acc: 0.0049    \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(200, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x=training_images, y=training_labels, batch_size=128,\n",
    "                 epochs=30, callbacks=[TestCallback((val_images, val_labels))])\n",
    "#score,acc = model.evaluate(val_images, val_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
