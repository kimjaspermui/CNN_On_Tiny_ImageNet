{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, ZeroPadding2D, BatchNormalization, AveragePooling2D\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses\n",
    "from keras import utils\n",
    "from keras import callbacks\n",
    "from keras import initializers\n",
    "import keras\n",
    "import h5py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "# constants\n",
    "CLASS = 200\n",
    "TRAIN_PER_CLASS = 400\n",
    "VAL_PER_CLASS = 100\n",
    "TOTAL_SAMPLES = CLASS * (TRAIN_PER_CLASS + VAL_PER_CLASS)\n",
    "COLOR_CHANNELS = 3\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_HEIGHT = 64\n",
    "TEST_SAMPLES = 10000\n",
    "\n",
    "# read all of the word net id\n",
    "wnids = [id.strip('\\n') for id in open('/datasets/tmp/cg181fdn/tiny-imagenet-200/wnids.txt').readlines()]\n",
    "\n",
    "# data will store all of the data\n",
    "data = {}\n",
    "\n",
    "# train data\n",
    "data['train'] = {}\n",
    "data['train']['data'] = np.ndarray(shape=(TRAIN_PER_CLASS * CLASS, IMAGE_WIDTH, IMAGE_HEIGHT, COLOR_CHANNELS), dtype=np.uint8)\n",
    "data['train']['target'] = np.ndarray(shape=(TRAIN_PER_CLASS * CLASS,), dtype=np.uint8)\n",
    "\n",
    "# validation data\n",
    "data['val'] = {}\n",
    "data['val']['data'] = np.ndarray(shape=(VAL_PER_CLASS * CLASS, IMAGE_WIDTH, IMAGE_HEIGHT, COLOR_CHANNELS), dtype=np.uint8)\n",
    "data['val']['target'] = np.ndarray(shape=(VAL_PER_CLASS * CLASS,), dtype=np.uint8)\n",
    "\n",
    "# validation data\n",
    "data['test'] = {}\n",
    "data['test']['data'] = np.ndarray(shape=(TEST_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, COLOR_CHANNELS), dtype=np.uint8)\n",
    "data['test']['target'] = np.ndarray(shape=(TEST_SAMPLES,), dtype=np.uint8)\n",
    "\n",
    "# iterate through work net ids\n",
    "print(\"storing training and validation:\")\n",
    "for i in range(len(wnids)):\n",
    "    wnid = wnids[i]\n",
    "    print(\"%s: %d / %d\" % (wnid, i + 1, len(wnids)))\n",
    "    for j in range(TRAIN_PER_CLASS):\n",
    "        temp = []\n",
    "        path = \"/datasets/tmp/cg181fdn/tiny-imagenet-200/train/{0}/images/{0}_{1}.JPEG\".format(wnid, j)\n",
    "        data['train']['data'][i * TRAIN_PER_CLASS + j] = np.array(Image.open(path).convert('RGB'))\n",
    "        data['train']['target'][i * TRAIN_PER_CLASS + j] = wnids.index(wnid)\n",
    "    for j in range(TRAIN_PER_CLASS, TRAIN_PER_CLASS + VAL_PER_CLASS):\n",
    "        temp = []\n",
    "        path = \"/datasets/tmp/cg181fdn/tiny-imagenet-200/train/{0}/images/{0}_{1}.JPEG\".format(wnid, j)\n",
    "        data['val']['data'][i * VAL_PER_CLASS + j-TRAIN_PER_CLASS] = np.array(Image.open(path).convert('RGB'))\n",
    "        data['val']['target'][i * VAL_PER_CLASS + j-TRAIN_PER_CLASS] = wnids.index(wnid)\n",
    "\n",
    "# get the validation data\n",
    "print(\"storing testing:\")\n",
    "for i, line in enumerate(map(lambda s: s.strip(), open('/datasets/tmp/cg181fdn/tiny-imagenet-200/val/val_annotations.txt'))):\n",
    "    print(\"%d/%d\" % (i+1, 10000))\n",
    "    name, wnid = line.split('\\t')[0:2]\n",
    "    temp = []\n",
    "    path = \"/datasets/tmp/cg181fdn/tiny-imagenet-200/val/images/{0}\".format(name)\n",
    "    data['test']['data'][i] = np.array(Image.open(path).convert('RGB'))\n",
    "    data['test']['target'][i] = wnids.index(wnid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestCallback(callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "        \n",
    "def saveModel(myModel, modelPath, weightPath):\n",
    "    # serialize model to JSON then store to file\n",
    "    model_json = myModel.to_json()\n",
    "    with open(modelPath, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        \n",
    "    # serialize weights to HDF5\n",
    "    myModel.save_weights(weightPath)\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "def loadModel(modelPath, weightPath):\n",
    "    # load json and create model\n",
    "    json_file = open(modelPath, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "    \n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(weightPath)\n",
    "    print(\"Loaded model from disk\")\n",
    "    \n",
    "    return loaded_model\n",
    "\n",
    "def storeResult(filename, title, myHist, testAcc):\n",
    "    file = open(filename, 'w')\n",
    "    file.write(title)\n",
    "    file.write(\"--- Training: acc/loss ---\\n\")\n",
    "    for acc, loss in zip(myHist.history[\"acc\"], myHist.history[\"loss\"]):\n",
    "        file.write(str(acc)+\"$\"+str(loss)+\"\\n\")\n",
    "    file.write(\"--- Validation: acc/loss ---\\n\")\n",
    "    for acc, loss in zip(myHist.history[\"val_acc\"], myHist.history[\"val_loss\"]):\n",
    "        file.write(str(acc)+\"$\"+str(loss)+\"\\n\")\n",
    "    file.write(testAcc)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_like():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-6,l2=1e-6)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(200, activation='softmax',\n",
    "                   kernel_regularizer=regularizers.l1_l2(l1=1e-5,l2=1e-5)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_16():    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1), input_shape=(64,64,3)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name=\"conv1_1\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name=\"conv1_2\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), name=\"block1_pool\"))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', name=\"conv2_1\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', name=\"conv2_2\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), name=\"block2_pool\"))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', name=\"conv3_1\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', name=\"conv3_2\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', name=\"conv3_3\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), name=\"block3_pool\"))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', name=\"conv4_1\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', name=\"conv4_2\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu', name=\"conv4_3\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), name=\"block4_pool\"))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu',\n",
    "                     kernel_regularizer=regularizers.l1_l2(l1=1e-7,l2=1e-7), name=\"conv5_1\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu',\n",
    "                     kernel_regularizer=regularizers.l1_l2(l1=1e-6,l2=1e-6), name=\"conv5_2\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='relu',\n",
    "                     kernel_regularizer=regularizers.l1_l2(l1=1e-5,l2=1e-5), name=\"conv5_3\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), name=\"block5_pool\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-4,l2=1e-4), name=\"fc6\"))\n",
    "    model.add(Dropout(0.75, name=\"drop6\"))\n",
    "    model.add(Dense(4096, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=1e-4,l2=1e-4), name=\"fc7\"))\n",
    "    model.add(Dropout(0.75, name=\"drop7\"))\n",
    "    model.add(Dense(200, activation='softmax', name=\"fc8\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alexnet():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(11, 11), activation='relu', input_shape=(64,64,3)))    \n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1,1)))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=(7, 7), activation='relu'))    \n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1,1)))\n",
    "\n",
    "    model.add(Conv2D(filters=192, kernel_size=(3, 3), activation='relu'))    \n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1,1)))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))    \n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(1,1)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "    model.add(Dense(200, activation='softmax'))\n",
    "    model.add(BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lenet():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(20, (5, 5), padding='same', activation='relu', input_shape=(64,64,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(50, (5, 5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.9))\n",
    "    model.add(Dense(200, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myModel1(pool, myActivation):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (2, 2), activation=myActivation, padding='same', input_shape=(64,64,3)))\n",
    "    model.add(pool)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (2, 2), activation=myActivation, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(pool)\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (2, 2), activation=myActivation, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(pool)\n",
    "    model.add(Conv2D(128, (2, 2), activation=myActivation, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(pool)\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(256, (2, 2), activation=myActivation, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(pool)\n",
    "    model.add(Conv2D(256, (2, 2), activation=myActivation, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(pool)\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=myActivation, kernel_regularizer=regularizers.l1_l2(l1=1e-6,l2=1e-6)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(200, activation='softmax', kernel_regularizer=regularizers.l1_l2(l1=1e-5,l2=1e-5)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myModel2():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (2, 2), activation='relu', padding='same', input_shape=(64,64,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (2, 2), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (2, 2), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (2, 2), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-6,l2=1e-6)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(200, activation='softmax', kernel_regularizer=regularizers.l1_l2(l1=1e-5,l2=1e-5)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myModel3():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (2, 2), activation='relu', padding='same', input_shape=(64,64,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (2, 2), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-6,l2=1e-6)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(200, activation='softmax', kernel_regularizer=regularizers.l1_l2(l1=1e-5,l2=1e-5)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_x = np.array(data['train']['data'])\n",
    "train_y = np.array(data['train']['target'])\n",
    "train_y = utils.to_categorical(train_y, num_classes=200)\n",
    "\n",
    "val_x = np.array(data['val']['data'])\n",
    "val_y = np.array(data['val']['target'])\n",
    "val_y = utils.to_categorical(val_y, num_classes=200)\n",
    "\n",
    "test_x = np.array(data['test']['data'])\n",
    "test_y = np.array(data['test']['target'])\n",
    "test_y = utils.to_categorical(test_y, num_classes=200)\n",
    "\n",
    "myModel = myModel1(AveragePooling2D(pool_size=(2, 2)), 'relu')\n",
    "\n",
    "# compile the model\n",
    "op = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "myModel.compile(loss='categorical_crossentropy', optimizer=op, metrics=['accuracy'])\n",
    "\n",
    "# fit and evaluate\n",
    "hist = myModel.fit(x=train_x, y=train_y, batch_size=128, validation_data=(val_x, val_y), shuffle=True,\n",
    "                   initial_epoch=0, epochs=100,\n",
    "                   callbacks=[TestCallback((test_x, test_y))])\n",
    "testScore = myModel.evaluate(test_x, test_y, verbose=0)\n",
    "testAccuracy = \"Test Accuracy: %.2f%%\" % (testScore[1]*100)\n",
    "print(testAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultFilename = \"./Results/model1.txt\"\n",
    "storeResult(resultFilename, \"model1 Adam {lr: 1e-4, epoch: 100}\\n\", hist, testAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and weight paths\n",
    "modelPath = \"./Models/model1-model Adam {epoch: 100}.json\"\n",
    "weightPath = \"./Models/model1-model Adam {epoch: 100}.h5\"\n",
    "\n",
    "# store model\n",
    "saveModel(myModel, modelPath, weightPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempting transfer learning\n",
    "op = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "modelPath = \"./Models/model1_avg-weight Adam {epoch: 100}.json\"\n",
    "weightPath = \"./Models/model1_avg-model Adam {epoch: 100}.h5\"\n",
    "\n",
    "# load model\n",
    "loadedModel = loadModel(modelPath, weightPath)\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loadedModel.compile(loss='categorical_crossentropy', optimizer=op, metrics=['accuracy'])\n",
    "score = loadedModel.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loadedModel.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue fitting\n",
    "hist = myModel.fit(x=train_x, y=train_y, batch_size=32, validation_data=(val_x, val_y), shuffle=True,\n",
    "                   initial_epoch=100, epochs=200,\n",
    "                   callbacks=[TestCallback((test_x, test_y))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
