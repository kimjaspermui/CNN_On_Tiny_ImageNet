{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-827a81430458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import requests, StringIO\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "NUM_CLASSES = 200\n",
    "NUM_IMAGES_PER_CLASS = 500\n",
    "NUM_IMAGES = NUM_CLASSES * NUM_IMAGES_PER_CLASS\n",
    "TRAINING_IMAGES_DIR = './tiny-imagenet-200/train/'\n",
    "TRAIN_SIZE = NUM_IMAGES\n",
    "\n",
    "NUM_VAL_IMAGES = 10000\n",
    "VAL_IMAGES_DIR = './tiny-imagenet-200/val/'\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "NUM_CHANNELS = 3\n",
    "IMAGE_ARR_SIZE = IMAGE_SIZE * IMAGE_SIZE * NUM_CHANNELS\n",
    "IMAGES_URL = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(url):\n",
    "    if (os.path.isdir(TRAINING_IMAGES_DIR)):\n",
    "        print ('Images already downloaded...')\n",
    "        return\n",
    "    r = requests.get(url, stream=True)\n",
    "    print ('Downloading ' + url )\n",
    "    zip_ref = zipfile.ZipFile(StringIO.StringIO(r.content))\n",
    "    zip_ref.extractall('./')\n",
    "    zip_ref.close()\n",
    "    \n",
    "def load_training_images(image_dir, batch_size=500):\n",
    "\n",
    "    image_index = 0\n",
    "    \n",
    "    images = np.ndarray(shape=(NUM_IMAGES, IMAGE_ARR_SIZE))\n",
    "    names = []\n",
    "    labels = []                       \n",
    "    \n",
    "    # Loop through all the types directories\n",
    "    for type in os.listdir(image_dir):\n",
    "        if os.path.isdir(image_dir + type + '/images/'):\n",
    "            type_images = os.listdir(image_dir + type + '/images/')\n",
    "            # Loop through all the images of a type directory\n",
    "            batch_index = 0;\n",
    "            #print (\"Loading Class \", type)\n",
    "            for image in type_images:\n",
    "                image_file = os.path.join(image_dir, type + '/images/', image)\n",
    "\n",
    "                # reading the images as they are; no normalization, no color editing\n",
    "                image_data = mpimg.imread(image_file) \n",
    "                #print ('Loaded Image', image_file, image_data.shape)\n",
    "                if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "                    images[image_index, :] = image_data.flatten()\n",
    "\n",
    "                    labels.append(type)\n",
    "                    names.append(image)\n",
    "                    \n",
    "                    image_index += 1\n",
    "                    batch_index += 1\n",
    "                if (batch_index >= batch_size):\n",
    "                    break;\n",
    "                    \n",
    "    return (images, np.asarray(labels), np.asarray(names))\n",
    "\n",
    "def get_label_from_name(data, name):\n",
    "    for idx, row in data.iterrows():       \n",
    "        if (row['File'] == name):\n",
    "            return row['Class']\n",
    "        \n",
    "    return None\n",
    "\n",
    "\n",
    "def load_validation_images(testdir, validation_data, batch_size=NUM_VAL_IMAGES):\n",
    "    labels = []\n",
    "    names = []\n",
    "    image_index = 0\n",
    "    \n",
    "    images = np.ndarray(shape=(batch_size, IMAGE_ARR_SIZE))\n",
    "    val_images = os.listdir(testdir + '/images/')\n",
    "           \n",
    "    # Loop through all the images of a val directory\n",
    "    batch_index = 0;\n",
    "    \n",
    "    \n",
    "    for image in val_images:\n",
    "        image_file = os.path.join(testdir, 'images/', image)\n",
    "        #print (testdir, image_file)\n",
    "\n",
    "        # reading the images as they are; no normalization, no color editing\n",
    "        image_data = mpimg.imread(image_file) \n",
    "        if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "            images[image_index, :] = image_data.flatten()\n",
    "            image_index += 1\n",
    "            labels.append(get_label_from_name(validation_data, image))\n",
    "            names.append(image)\n",
    "            batch_index += 1\n",
    "            \n",
    "        if (batch_index >= batch_size):\n",
    "            break;\n",
    "    \n",
    "    print (\"Loaded Validation images \", image_index)\n",
    "    return (images, np.asarray(labels), np.asarray(names))\n",
    "   \n",
    "def plot_object(data):\n",
    "    plt.figure(figsize=(1,1))\n",
    "    image = data.reshape(IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_objects(instances, images_per_row=10, **options):\n",
    "    size = IMAGE_SIZE\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size,NUM_CHANNELS) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        if (row == len(instances)/images_per_row):\n",
    "            break\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, **options)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def get_next_batch(batchsize=50):\n",
    "    for cursor in range(0, len(training_images), batchsize):\n",
    "        batch = []\n",
    "        batch.append(training_images[cursor:cursor+batchsize])\n",
    "        batch.append(training_labels_encoded[cursor:cursor+batchsize])       \n",
    "        yield batch\n",
    "\n",
    "def get_next_labels(batchsize=50):\n",
    "    for cursor in range(0, len(training_images), batchsize):\n",
    "        yield training_labels_encoded[cursor:cursor+batchsize]  \n",
    "    \n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_images(IMAGES_URL)\n",
    "training_images, training_labels, training_files = load_training_images(TRAINING_IMAGES_DIR, batch_size=BATCH_SIZE)\n",
    "\n",
    "shuffle_index = np.random.permutation(len(training_labels))\n",
    "training_images = training_images[shuffle_index]\n",
    "training_labels = training_labels[shuffle_index]\n",
    "training_files  = training_files[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
